{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64baa713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the full pipeline for the text anaylsis\n",
    "#There are two main components of analysis.\n",
    "    #1. Persuasion detection \n",
    "    #2. Analysis to classify arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d5c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85384dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: Persuasion detection\n",
    "#In this part, we are using a classified machine learning algorithm. It is\n",
    "#Trained on ~70k reddit posts/comments that were gathered using PRAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe97af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffb1c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    47303\n",
       "1    30890\n",
       "Name: containsPersuasion, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('etc/persuasionExamples6.csv', encoding = \"latin1\", engine='python', usecols=['body', 'containsPersuasion'])\n",
    "data['containsPersuasion'] = np.where(data['containsPersuasion']=='[1]', 1, 0)\n",
    "data = data.astype('U')\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['body'] = data['body']\n",
    "trainDF['containsPersuasion'] = data['containsPersuasion']\n",
    "data['containsPersuasion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c819a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['body'], trainDF['containsPersuasion'])\n",
    "train_x = train_x.astype('U')\n",
    "valid_x = valid_x.astype('U')\n",
    "train_y = train_y.astype('U')\n",
    "valid_y = valid_y.astype('U')\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412ea9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up Count Vectorizer used in all 'XXCV' models.\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['body'])\n",
    "\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c55308aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up Word Vectorizer used in all 'XXWV' models.\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['body'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a1a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up N-gram Vectorizer used in all 'XXNV' models.\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainDF['body'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c31c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "def train_model(classifier, feature_vector_train, label):#, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    return classifier\n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480f54aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBCV:  0.7810118164612001\n",
      "NBWV:  0.8701723873343905\n",
      "NBNV:  0.8388664381809812\n"
     ]
    }
   ],
   "source": [
    "#Creates model using above function, notice which training sets are passed for which model\n",
    "# Naive Bayes on Count Vectors\n",
    "nbcv = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y)\n",
    "predictions = nbcv.predict(xvalid_count)\n",
    "print(\"NBCV: \", metrics.accuracy_score(predictions, valid_y))\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "nbwv = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y)\n",
    "predictions = nbwv.predict(xvalid_tfidf)\n",
    "print(\"NBWV: \", metrics.accuracy_score(predictions, valid_y))\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "nbnv = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y)\n",
    "predictions = nbnv.predict(xvalid_tfidf_ngram)\n",
    "print(\"NBNV: \", metrics.accuracy_score(predictions, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8702947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRCV:  0.9116067318021382\n",
      "LRWV:  0.9083329070540692\n",
      "LRNV:  0.8654662642590414\n"
     ]
    }
   ],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "lrcv = train_model(linear_model.LogisticRegression(max_iter=1000000), xtrain_count, train_y)\n",
    "predictions = lrcv.predict(xvalid_count)\n",
    "print(\"LRCV: \", metrics.accuracy_score(predictions, valid_y))\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "lrwv = train_model(linear_model.LogisticRegression(max_iter=1000000), xtrain_tfidf, train_y)\n",
    "predictions = lrwv.predict(xvalid_tfidf)\n",
    "print(\"LRWV: \", metrics.accuracy_score(predictions, valid_y))\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "lrnv = train_model(linear_model.LogisticRegression(max_iter=1000000), xtrain_tfidf_ngram, train_y)\n",
    "predictions = lrnv.predict(xvalid_tfidf_ngram)\n",
    "print(\"LRNV: \", metrics.accuracy_score(predictions, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44681aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual testing, now that we have the classifiers trained, we can pass in our own tests.\n",
    "man_data = pd.read_csv('etc/testSet3.csv', encoding = \"latin1\", engine='python', usecols=['body', 'containsPersuasion'])\n",
    "man_x = man_data.body\n",
    "man_y = man_data.containsPersuasion\n",
    "#Have to use previous vectors.transform(man_x) to get right demensiosn.\n",
    "man_x_cv = count_vect.transform(man_x)\n",
    "man_x_wv = tfidf_vect.transform(man_x)\n",
    "man_x_nv = tfidf_vect_ngram.transform(man_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc149d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBCV:  0.8\n"
     ]
    }
   ],
   "source": [
    "predictions = nbcv.predict(man_x_cv)\n",
    "print(\"NBCV: \", metrics.accuracy_score(predictions, man_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbe423b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBWV:  0.64\n"
     ]
    }
   ],
   "source": [
    "predictions = nbwv.predict(man_x_wv)\n",
    "print(\"NBWV: \", metrics.accuracy_score(predictions, man_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97d49f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NBNV:  0.76\n"
     ]
    }
   ],
   "source": [
    "predictions = nbnv.predict(man_x_nv)\n",
    "print(\"NBNV: \", metrics.accuracy_score(predictions, man_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc404054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRCV:  0.64\n"
     ]
    }
   ],
   "source": [
    "predictions = lrcv.predict(man_x_cv)\n",
    "print(\"LRCV: \", metrics.accuracy_score(predictions, man_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bd4735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRWV:  0.64\n"
     ]
    }
   ],
   "source": [
    "predictions = lrwv.predict(man_x_wv)\n",
    "print(\"LRWV: \", metrics.accuracy_score(predictions, man_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa4d8766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRNV:  0.66\n"
     ]
    }
   ],
   "source": [
    "predictions = lrnv.predict(man_x_nv)\n",
    "print(\"LRNV: \", metrics.accuracy_score(predictions, man_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b087327c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  3]\n",
      " [ 9 16]]\n"
     ]
    }
   ],
   "source": [
    "#Printing off confusion matrix of a specific algorithm\n",
    "#[is not persuasive and guessed right, is not persuasive but guessed wrong]\n",
    "#[Is persuasive but guessed wrong, is persuasicve and guessed right]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = nbnv.predict(man_x_nv)\n",
    "confusion_matrix = confusion_matrix(man_y, predictions)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd7cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9afa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part two: Analysis to classify argument \n",
    "#In this part, we take all examples that were marked as persuasivem and do\n",
    "#Further analysis on them to estimate the classification of argument (Between \n",
    "#Logos, Ethos, and Pathos). Originally we wanted to do this via an unsupervised\n",
    "#algorithm, but have switched to a range of manual tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cf71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0eb81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccc5f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a541d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97394d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c47403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
